{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a2afc4",
   "metadata": {
    "id": "15a2afc4"
   },
   "source": [
    "# Hand Gesture RGB dataset (.csv) creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccb9f6",
   "metadata": {
    "id": "6eccb9f6"
   },
   "outputs": [],
   "source": [
    "# Institution: Carleton University\n",
    "# Course: OSS4900 Capstone \n",
    "# Term: F22 - W23\n",
    "#\n",
    "# Filename: 0 - Pre1 - csv_dataset_creation.ipynb\n",
    "#\n",
    "# Students: Adam Thompson, Philippe Beaulieu\n",
    "# Advisor:  Dr. Marzieh Amini\n",
    "#\n",
    "# Description: This program will create the dataset from the landmark taken from\n",
    "#              Mediapipe Hand, they are saved in a .csv format under dataset_filename.\n",
    "#              You can test the landmark with an image or live stream with a webcam in\n",
    "#              the bottom code sections\n",
    "#\n",
    "#              This program will only look at the RGB images to extract the landmark.\n",
    "#              The folder hierarchy is important to load the images, it is as follow:\n",
    "#\n",
    "#     TRAIN\n",
    "#       -DEPTH\n",
    "#          -folder0\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -folder1\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -...\n",
    "#       -RGB\n",
    "#          -folder0\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -folder1\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -...\n",
    "#     TEST -> follow the same structure as train\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b6f45",
   "metadata": {
    "id": "7f0b6f45"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca45460",
   "metadata": {
    "id": "7ca45460"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "mp_hands          = mp.solutions.hands\n",
    "mp_drawing        = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "points            = mp_hands.HandLandmark # Landmarks\n",
    "\n",
    "path   = \"TRAIN/RGB\" # enter dataset path\n",
    "\n",
    "data   = []\n",
    "\n",
    "for p in points:\n",
    "x = str(p)[13:]\n",
    "    data.append(x + \"_x\")\n",
    "    data.append(x + \"_y\")\n",
    "    data.append(x + \"_z\")\n",
    "data.append('target')               # added the target field depicting the group 0, 1, ...\n",
    "data = pd.DataFrame(columns = data) # Empty dataset\n",
    "\n",
    "dataset_filename = \"dataset3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81d008",
   "metadata": {
    "id": "0d81d008",
    "outputId": "aac33221-5fa5-42e5-d3be-335421df2ab2"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b4bef",
   "metadata": {
    "id": "5e7b4bef"
   },
   "source": [
    "Build the dataset (dataset3.csv) from images in a folder, and the class name taken from the folder name (class_name.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d3cce",
   "metadata": {
    "id": "b99d3cce",
    "outputId": "2e22d9c4-eacc-41c7-f2c1-2f76a817df38"
   },
   "outputs": [],
   "source": [
    "count  = 0\n",
    "countF = 0\n",
    "target = 0\n",
    "\n",
    "class_name = []\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=1, \n",
    "                    model_complexity=1, \n",
    "                    min_detection_confidence=0.6, \n",
    "                    min_tracking_confidence=0.6) as hands:\n",
    "        \n",
    "    for folder in os.listdir(path):\n",
    "        for img in os.listdir(path + \"/\" + folder):\n",
    "            temp = []\n",
    "            img  = cv2.imread(path + \"/\" + folder + \"/\" + img)\n",
    "            blackie = np.zeros(img.shape) # Blank image\n",
    "            results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(blackie, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                              mp_drawing_styles.get_default_hand_connections_style())\n",
    "                    #print(\"Pose Landmarks:\",hand_landmarks)\n",
    "\n",
    "                    for point in mp_hands.HandLandmark:\n",
    "                        nLandmark = hand_landmarks.landmark[point]\n",
    "                        temp = temp + [nLandmark.x, nLandmark.y, nLandmark.z]\n",
    "                        \n",
    "                temp = temp + [target]\n",
    "\n",
    "                #print(\"Pose temp:\",temp)\n",
    "                \n",
    "                data.loc[count] = temp\n",
    "                count +=1\n",
    "\n",
    "            countF += 1  # add to valid image count\n",
    "            cv2.imshow(\"Image\", img)\n",
    "            cv2.imshow(\"blackie\",blackie)\n",
    "            cv2.waitKey(10)\n",
    "\n",
    "        target += 1   # add the count of image\n",
    "        # add the folder name in a target list of actions\n",
    "        class_name.append(folder)\n",
    "\n",
    "data.to_csv(dataset_filename) # save the data as a csv file\n",
    "\n",
    "with open(\"class_name.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable if the data is nested\n",
    "    json.dump(class_name, f, indent=2) \n",
    "\n",
    "print(\"Valid images:\",count)\n",
    "print(\"Total Images:\",countF)\n",
    "print(\"Class Name:\",class_name)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22142d4",
   "metadata": {
    "id": "a22142d4"
   },
   "source": [
    "Testing for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f03ec",
   "metadata": {
    "id": "206f03ec",
    "outputId": "632d96a9-3f8d-49b2-9da5-e26be219df4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dataset_filename = \"dataset3.csv\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data              = pd.read_csv(dataset_filename,index_col=0) \n",
    "features,labels   = data.iloc[:,:63],data['target']\n",
    "\n",
    "#{using SVC}\n",
    "#model   = SVC(kernel = 'rbf')\n",
    "\n",
    "#{using K Neighbors Classifier}  - good standing and sitting\n",
    "model   = KNeighborsClassifier() # Initialize our classifier\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.20,\n",
    "                                                          random_state=13)\n",
    "# fit the data into the model\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "# make a prediction\n",
    "preds = model.predict(test)\n",
    "#print(\"Prediction:\", preds)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(test_labels, preds))\n",
    "\n",
    "#Get the confusion matrix\n",
    "cf_matrix1 = confusion_matrix(test_labels, preds)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(111)\n",
    "sns.heatmap(cf_matrix1/np.sum(cf_matrix1), annot=True, fmt='.2%')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title('Confusion Matrix: K Neighbors Classifier:')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a315b",
   "metadata": {
    "id": "f21a315b"
   },
   "source": [
    "Test an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862ae25",
   "metadata": {
    "id": "b862ae25",
    "outputId": "4c88e7f4-3d55-46a5-c05e-a5a440d1f96b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset_filename = \"dataset3.csv\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Colors.\n",
    "blue        = (255, 127, 0)\n",
    "green       = (127, 255, 0)\n",
    "dark_blue   = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow      = (0, 255, 255)\n",
    "pink        = (255, 0, 255)\n",
    "red         = (50, 50, 255)\n",
    "\n",
    "colors = blue\n",
    "asan = \"\"\n",
    "\n",
    "mp_hands          = mp.solutions.hands\n",
    "mp_drawing        = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "data              = pd.read_csv(dataset_filename,index_col=0) \n",
    "features,labels   = data.iloc[:,:63],data['target']\n",
    "\n",
    "#{using SVC}\n",
    "#model   = SVC(kernel = 'rbf')\n",
    "\n",
    "#{using K Neighbors Classifier}  - good standing and sitting\n",
    "model = KNeighborsClassifier() # Initialize our classifier\n",
    "\n",
    "model.fit(features,labels)\n",
    "\n",
    "with open(\"class_name.json\", 'r') as f:\n",
    "    class_name = json.load(f)\n",
    "\n",
    "file    = \"TEST/RGB/fist/frame592.jpg\"   # \"enter image path\"\n",
    "#file    = \"TEST/DEPTH/fist/frame592.jpg\"   # \"enter image path\"\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=1, \n",
    "                    model_complexity=0, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    img     = cv2.imread(file)\n",
    "    #blackim = np.zeros(img.shape) # Blank image\n",
    "    ttemp   = []\n",
    "\n",
    "    results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                      mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                      mp_drawing_styles.get_default_hand_connections_style())\n",
    "            #print(\"Hand Landmarks:\",hand_landmarks)\n",
    "\n",
    "            for point in mp_hands.HandLandmark:\n",
    "                nLandmark = hand_landmarks.landmark[point]\n",
    "                ttemp = ttemp + [nLandmark.x, nLandmark.y, nLandmark.z]\n",
    "\n",
    "        preds = model.predict([ttemp])\n",
    "        asan = class_name[int(preds)]\n",
    "        if (int(preds) == 0):\n",
    "            colors = green\n",
    "        elif (int(preds) == 1):\n",
    "            colors = light_green\n",
    "        elif (int(preds) == 2):\n",
    "            colors = yellow\n",
    "        elif (int(preds) == 3):\n",
    "            colors = pink\n",
    "        else:\n",
    "            colors = red \n",
    "        \n",
    "        print(asan)\n",
    "        print(\"Prediction:\",preds)\n",
    "\n",
    "        #mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS) #draw landmarks on image\n",
    "        #mpDraw.draw_landmarks(blackim, results.pose_landmarks, mpPose.POSE_CONNECTIONS) # draw landmarks on blackie\n",
    "        cv2.putText(img, asan, (50,50), cv2.FONT_HERSHEY_SIMPLEX,1,colors,3)\n",
    "\n",
    "        cv2.imshow(\"Intel D435 Hand Gesture\",img)\n",
    "        #cv2.imshow(\"Hand Landmarks\",blackim)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e7f67",
   "metadata": {
    "id": "728e7f67"
   },
   "source": [
    "Test using a regular webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfb5f4",
   "metadata": {
    "id": "f8cfb5f4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dataset_filename = \"dataset3.csv\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Colors.\n",
    "green       = (127, 255, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow      = (0, 255, 255)\n",
    "pink        = (255, 0, 255)\n",
    "red         = (50, 50, 255)\n",
    "blue        = (255, 127, 0)\n",
    "dark_blue   = (127, 20, 0)\n",
    "\n",
    "colors = green\n",
    "asan = \"\"\n",
    "\n",
    "mp_hands          = mp.solutions.hands\n",
    "mp_drawing        = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "data        = pd.read_csv(dataset_filename,index_col=0) \n",
    "feat, label = data.iloc[:,:63],data['target']\n",
    "\n",
    "#{using SVC}\n",
    "#model   = SVC(kernel = 'rbf')\n",
    "\n",
    "#{using K Neighbors Classifier}  - good standing and sitting\n",
    "model = KNeighborsClassifier() # Initialize our classifier\n",
    "\n",
    "model.fit(feat, label) # Train our classifier\n",
    "\n",
    "\n",
    "with open(\"class_name.json\", 'r') as f:\n",
    "    class_name = json.load(f)\n",
    "\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(3)      # use your webcam number location, '0' is the first camera/app\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=1, \n",
    "                    model_complexity=0, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # process the image to extract the hand landmark (coordinates)\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        ttemp   = []\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                          mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                # extract the landmark\n",
    "                for point in mp_hands.HandLandmark:\n",
    "                    nLandmark = hand_landmarks.landmark[point]\n",
    "                    ttemp = ttemp + [nLandmark.x, nLandmark.y, nLandmark.z]\n",
    "\n",
    "            # make prediction, identify the action, select color of text\n",
    "            preds = model.predict([ttemp])\n",
    "            asan = class_name[int(preds)]      \n",
    "            if (int(preds) == 0):\n",
    "                colors = green\n",
    "            elif (int(preds) == 1):\n",
    "                colors = light_green\n",
    "            elif (int(preds) == 2):\n",
    "                colors = yellow\n",
    "            elif (int(preds) == 3):\n",
    "                colors = pink\n",
    "            else:\n",
    "                colors = red                \n",
    "\n",
    "        # Draw the pose annotation on the image.\n",
    "        cv2.putText(image, asan, (50,50), cv2.FONT_HERSHEY_SIMPLEX,1,colors,3)\n",
    "\n",
    "        # display the image\n",
    "        cv2.imshow('MediaPipe Hand', image)\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26986b21",
   "metadata": {
    "id": "26986b21"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
