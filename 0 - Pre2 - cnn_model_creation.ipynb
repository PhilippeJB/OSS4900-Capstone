{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXMhXU4nsp7Z"
   },
   "source": [
    "# Hand Gesture CNN model creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS1zNRNCX969"
   },
   "outputs": [],
   "source": [
    "# Institution: Carleton University\n",
    "# Course: OSS4900 Capstone \n",
    "# Term: F22 - W23\n",
    "#\n",
    "# Filename: 0 - Pre2 - cnn_model_creation.ipynb\n",
    "#\n",
    "# Students: Adam Thompson, Philippe Beaulieu\n",
    "# Advisor:  Dr. Marzieh Amini\n",
    "#\n",
    "# Description: This program will create the model from images in a folder structure,\n",
    "#              and trained, the model can be converted to a Tensorflow light and saved.\n",
    "#              You can test the mode with an image or live stream with a webcam in\n",
    "#              the bottom code sections\n",
    "#              You can save the model to a Tensorflow Light Model after testing the\n",
    "#              training and validation\n",
    "#\n",
    "#              This program will only look at the DEPTH images for the Tensorflow model.\n",
    "#              The folder hierarchy is important to load the images, it is as follow:\n",
    "#\n",
    "#     TRAIN\n",
    "#       -DEPTH\n",
    "#          -folder0\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -folder1\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -...\n",
    "#       -RGB\n",
    "#          -folder0\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -folder1\n",
    "#             - image0.jpg\n",
    "#             - image1.jpg\n",
    "#             - image2.jpg\n",
    "#             - ...\n",
    "#          -...\n",
    "#     TEST -> follow the same structure as train\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEB6GG7jX96_"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaf3X-nVsp7a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ0ywv5gsp7b"
   },
   "source": [
    "setting up the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3264,
     "status": "ok",
     "timestamp": 1675805657174,
     "user": {
      "displayName": "P Beaulieu (TGClerics)",
      "userId": "08279420019805274378"
     },
     "user_tz": 300
    },
    "id": "q-GjC3rUsp7c",
    "outputId": "ca9e6e36-6a0d-411f-c6d7-5f20cc2b784c"
   },
   "outputs": [],
   "source": [
    "#data_dir = pathlib.Path(archive).with_suffix('')\n",
    "data_dir = pathlib.Path('TRAIN/DEPTH').with_suffix('')\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcytsup9sp7d"
   },
   "source": [
    "Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1629,
     "status": "ok",
     "timestamp": 1675805682736,
     "user": {
      "displayName": "P Beaulieu (TGClerics)",
      "userId": "08279420019805274378"
     },
     "user_tz": 300
    },
    "id": "tE_yweMesp7e",
    "outputId": "388a5abd-466f-40b3-87ee-91f034de5bc8"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#img_height = 270\n",
    "#img_width  = 480\n",
    "img_height = 120\n",
    "img_width  = 160\n",
    "\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  labels='inferred',\n",
    "  color_mode='rgb',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=27,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  labels='inferred',\n",
    "  color_mode='rgb',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=27,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1675805691972,
     "user": {
      "displayName": "P Beaulieu (TGClerics)",
      "userId": "08279420019805274378"
     },
     "user_tz": 300
    },
    "id": "FyiZ8D_gsp7e",
    "outputId": "9559883c-dd11-4295-9039-4edb71091a3d"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPzIwlqasp7f"
   },
   "source": [
    "Visualize the data (no need to be run unless you are curious of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ff3Mb_Ksp7g"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK66_o4Isp7h"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrIrDJHmsp7i"
   },
   "source": [
    "Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkd-5FzUsp7k"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#train_ds = train_ds.cache().shuffle(1024).prefetch(buffer_size=AUTOTUNE)\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yU-euC5WX97G"
   },
   "source": [
    "Create the model - network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_wYuyoOsp7k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),     # Normalize the input data\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(256, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(256, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(512, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Conv2D(512, 3, padding='same', activation='relu', kernel_initializer='he_uniform'),\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5, input_shape=(2,)),   \n",
    "    layers.Dense(256, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Dense(64, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Dense(32, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Dropout(0.3, input_shape=(2,)),   \n",
    "    layers.Dense(num_classes, activation ='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VThspfr4X97H"
   },
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-vX5lXxsp7k",
    "outputId": "cae193b1-8e5f-45fd-bc30-9fe117505209",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvlWMcZ3X97I"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DumYKZCsp7l",
    "outputId": "5d3810d5-84f9-4381-85a0-b6e114860523",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=35\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFF5AUErX97J"
   },
   "source": [
    "Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdTRJ9oIX97J"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xIz_OaeX97J"
   },
   "outputs": [],
   "source": [
    "#model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqSDY9UcX97K"
   },
   "source": [
    "Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvSPd5TSX97K",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#img = tf.keras.utils.load_img('TEST/RGB/2finger/frame596.jpg', target_size=(img_height, img_width))\n",
    "img = tf.keras.utils.load_img('TEST/DEPTH/test1.png', target_size=(img_height, img_width))\n",
    "#img = tf.keras.utils.load_img('TRAIN/DEPTH/1finger/img333.jpg', target_size=(img_height, img_width))\n",
    "\n",
    "# preparing the image for prediction\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "# running the prediction on the image array\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "# display the image\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# print the prediction result\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score)) )\n",
    "print(predictions)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdDxf8YhX97K"
   },
   "source": [
    "Convert the Keras Sequential model to a TensorFlow Lite model - and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hIfS2jNX97Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "# Print the signatures from the converted model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "signatures  = interpreter.get_signature_list()\n",
    "print(signatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUKRMgWvX97R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1LdfWmTW94XzUdzRYniqwusvHlX1YVLN2",
     "timestamp": 1643382579159
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
